# Global configuration to prevent memory leaks and recursive scanning issues
# Note: Resource limits require Docker Compose v3.8+ and may require swarm mode
# For standalone Docker Desktop, these limits are advisory
x-common-resources: &common-resources
  limits:
    memory: 2G
  reservations:
    memory: 512M

services:
  timescaledb:
    image: timescale/timescaledb:latest-pg15
    container_name: arbees-timescaledb
    env_file:
      - .env
    ports:
      - "5432:5432"
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
      - ./shared/arbees_shared/db/migrations:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U arbees" ]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: arbees-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================================================
  # ZMQ Listener (Rust) - Observes all ZMQ traffic for logging and persistence
  # ==========================================================================
  # This service subscribes to ALL ZMQ publishers and provides:
  # - Structured console logging for debugging
  # - Redis streams for historical queries and slow-path consumers
  # - Optional file logging for replay/backtesting
  # - Latency tracking and sequence gap detection
  #
  # Modes:
  # - observer: Log and persist to streams only (default for zmq_only)
  # - bridge: Also forward to Redis pub/sub (for "both" transport mode)
  # - disabled: Exit immediately (for redis_only mode)
  # ==========================================================================
  zmq_listener:
    build:
      context: .
      dockerfile: services/zmq_listener_rust/Dockerfile
    container_name: arbees-zmq-listener
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # Listener mode (default: observer for ZMQ-only transport)
      ZMQ_LISTENER_MODE: "${ZMQ_LISTENER_MODE:-observer}"
      # ZMQ endpoints to subscribe to
      ZMQ_KALSHI_ENDPOINT: "tcp://kalshi_monitor:5555"
      ZMQ_POLYMARKET_ENDPOINT: "tcp://vpn:5556"
      ZMQ_GAME_SHARD_ENDPOINT: "tcp://game_shard:5558"
      ZMQ_SIGNAL_PROCESSOR_ENDPOINT: "tcp://signal_processor:5559"
      ZMQ_EXECUTION_ENDPOINT: "tcp://execution_service:5560"
      # Output configuration
      ZMQ_LISTENER_CONSOLE_LOG: "${ZMQ_LISTENER_CONSOLE_LOG:-true}"
      ZMQ_LISTENER_REDIS_STREAMS: "${ZMQ_LISTENER_REDIS_STREAMS:-true}"
      ZMQ_LISTENER_LOG_FORMAT: "${ZMQ_LISTENER_LOG_FORMAT:-pretty}"
      # Optional file logging (mount a volume if using)
      # ZMQ_LISTENER_LOG_FILE: "/var/log/arbees/zmq_traffic.jsonl"
    restart: unless-stopped
    profiles:
      - full
      - zmq

  # ==========================================================================
  # Notifications (Rust) - Signal via signal-cli-rest-api sidecar
  # ==========================================================================
  signal-cli-rest-api:
    image: bbernhard/signal-cli-rest-api:latest
    container_name: arbees-signal-cli-rest-api
    env_file:
      - .env
    ports:
      - "9922:8080"
    volumes:
      - signal_cli_data:/home/.local/share/signal-cli
    restart: unless-stopped
    profiles:
      - full

  notification_service_rust:
    build:
      context: .
      dockerfile: services/notification_service_rust/Dockerfile
    container_name: arbees-notification-service-rust
    depends_on:
      redis:
        condition: service_healthy
      signal-cli-rest-api:
        condition: service_started
    env_file:
      - .env
    restart: unless-stopped
    profiles:
      - full

  # ==========================================================================
  # Market Discovery (Rust) - NO VPN needed (Gamma API is public)
  # ==========================================================================
  market-discovery-rust:
    build:
      context: .
      dockerfile: services/market_discovery_rust/Dockerfile
    container_name: arbees-market-discovery
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    profiles:
      - full

  # ==========================================================================
  # Phase 4: Discovery Coordinator (orchestrator + market_discovery_rust)
  # ==========================================================================
  # These two services form a logical "discovery coordinator" unit:
  # - orchestrator: Game discovery (ESPN), shard assignment, health monitoring
  # - market-discovery-rust: Market ID lookup (Polymarket/Kalshi)
  #
  # They communicate via Redis pub/sub (discovery:requests / discovery:results).
  # In production, both should always be running together.
  # ==========================================================================

  orchestrator:
    build:
      context: .
      dockerfile: services/orchestrator_rust/Dockerfile
    container_name: arbees-orchestrator
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      market-discovery-rust:
        condition: service_started
    env_file:
      - .env
    # NOTE: No volume mount for Rust orchestrator - binary is compiled in image
    # Mount Docker socket only if supervisor functionality is needed
    # volumes:
    #   - /var/run/docker.sock:/var/run/docker.sock
    profiles:
      - full

  game_shard:
    build:
      context: .
      dockerfile: services/game_shard_rust/Dockerfile
    container_name: arbees-game-shard-rust
    # Resource limits to prevent memory exhaustion
    # Note: deploy.resources may require swarm mode; for standalone, use docker run --memory
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # ZMQ configuration for low-latency messaging
      ZMQ_SUB_ENDPOINTS: "tcp://kalshi_monitor:5555,tcp://vpn:5556"
      ZMQ_PUB_PORT: "5558"
      SHARD_TYPE: "sports"
      # Increase stack size to prevent overflow with deep async call stacks
      RUST_MIN_STACK: "8388608"
    expose:
      - "5558"
    ports:
      - "8001:80"
    volumes:
      - ./:/app
    profiles:
      - full

  # ==========================================================================
  # Crypto ZMQ Bridge - Polymarket prices from VPN to arbees-network
  # ==========================================================================
  # Polymarket monitor runs behind VPN (network_mode: "service:vpn")
  # Publishes to tcp://polymarket_monitor:5556 (unreachable from arbees-network)
  # This bridge subscribes from VPN and republishes on arbees-network
  # crypto_shard subscribes to this bridge at tcp://crypto-zmq-bridge:5564
  # ==========================================================================
  crypto-zmq-bridge:
    build:
      context: ./services/crypto_zmq_bridge
      dockerfile: Dockerfile
    container_name: arbees-crypto-zmq-bridge
    environment:
      LOG_LEVEL: "INFO"
      POLYMARKET_ZMQ_ENDPOINT: "tcp://vpn:5556"
      BRIDGE_PUB_ENDPOINT: "tcp://0.0.0.0:5564"
    depends_on:
      - polymarket_monitor
    expose:
      - "5564"
    restart: unless-stopped
    profiles:
      - full
      - crypto

  # ==========================================================================
  # Crypto Shard - Self-contained crypto arbitrage service
  # ==========================================================================
  # Monitors crypto events and emits execution requests via ZMQ
  # Bypasses signal_processor for <50ms latency
  # ==========================================================================
  crypto_shard:
    build:
      context: .
      dockerfile: services/crypto_shard_rust/Dockerfile
    container_name: arbees-crypto-shard
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      crypto-spot-monitor:
        condition: service_started
      crypto-zmq-bridge:
        condition: service_started
    env_file:
      - .env
    environment:
      RUST_LOG: info
      SHARD_TYPE: "crypto"
      CRYPTO_SHARD_ID: "crypto_1"
      # ZMQ price subscriptions: Direct ZMQ feeds (hot path, not Redis)
      # Endpoints:
      #   - kalshi_monitor:5555 (Kalshi prediction markets)
      #   - crypto-spot-monitor:5560 (Coinbase/Binance spot prices)
      #   - crypto-zmq-bridge:5564 (Polymarket via bridge)
      CRYPTO_PRICE_SUB_ENDPOINTS: "tcp://kalshi_monitor:5555,tcp://crypto-spot-monitor:5560,tcp://crypto-zmq-bridge:5564"
      CRYPTO_EXECUTION_PUB_ENDPOINT: "tcp://0.0.0.0:5559"
      # Risk management
      CRYPTO_MIN_EDGE_PCT: "3.0"
      CRYPTO_MAX_POSITION_SIZE: "500.0"
      CRYPTO_MAX_ASSET_EXPOSURE: "2000.0"
      CRYPTO_MAX_TOTAL_EXPOSURE: "5000.0"
      CRYPTO_VOLATILITY_SCALING: "true"
      CRYPTO_MIN_LIQUIDITY: "50.0"
      # Probability model
      CRYPTO_MODEL_VOLATILITY_WINDOW_DAYS: "30"
      CRYPTO_MODEL_TIME_DECAY: "true"
      CRYPTO_MODEL_MIN_CONFIDENCE: "0.60"
      # Monitoring
      CRYPTO_POLL_INTERVAL_SECS: "30"
      CRYPTO_PRICE_STALENESS_SECS: "60"
      CRYPTO_HEARTBEAT_INTERVAL_SECS: "5"
    expose:
      - "5559"
    ports:
      - "8002:80"
    volumes:
      - ./:/app
    profiles:
      - full
      - crypto

  api:
    build:
      context: .
      dockerfile: services/api/Dockerfile
    container_name: arbees-api
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "8000:8000"
    volumes:
      - ./:/app
    profiles:
      - full

  # ==========================================================================
  # Phase 1: Split Position Manager into Signal Processor + Execution + Tracker
  # ==========================================================================

  signal_processor:
    build:
      context: .
      dockerfile: services/signal_processor_rust/Dockerfile
    container_name: arbees-signal-processor-rust
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      market-discovery-rust:
        condition: service_started
    env_file:
      - .env
    environment:
      # ZMQ configuration for signal processing pipeline
      ZMQ_SUB_ENDPOINT: "tcp://game_shard:5558"
      ZMQ_PUB_PORT: "5559"
    expose:
      - "5559"
    profiles:
      - full

  execution_service:
    build:
      context: .
      dockerfile: services/execution_service_rust/Dockerfile
    container_name: arbees-execution-service-rust
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # ZMQ configuration for execution request processing
      ZMQ_SUB_ENDPOINT: "tcp://signal_processor:5559"
      # ZMQ PUB for trade results (observed by zmq_listener)
      ZMQ_PUB_PORT: "5560"
    expose:
      - "5560"
    volumes:
      - ./:/app
    profiles:
      - full

  position_tracker:
    build:
      context: .
      dockerfile: services/position_tracker_rust/Dockerfile
    container_name: arbees-position-tracker-rust
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      market-discovery-rust:
        condition: service_started
    env_file:
      - .env
    profiles:
      - full

  # Legacy position_manager (kept for backward compatibility, can be removed)
  position_manager:
    build:
      context: .
      dockerfile: services/position_manager/Dockerfile
    container_name: arbees-position-manager
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./:/app
    profiles:
      - legacy

  # ==========================================================================
  # Phase 2: Merged Analytics Service (archiver + ml_analyzer)
  # ==========================================================================

  analytics_service:
    build:
      context: .
      dockerfile: services/analytics_service/Dockerfile
    container_name: arbees-analytics
    deploy:
      resources:
        <<: *common-resources
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./:/app
      - ./reports:/app/reports
    profiles:
      - full

  # Legacy archiver (kept for backward compatibility)
  archiver:
    build:
      context: .
      dockerfile: services/archiver/Dockerfile
    container_name: arbees-archiver
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./:/app
    profiles:
      - legacy

  # Legacy ml_analyzer (kept for backward compatibility)
  ml_analyzer:
    build:
      context: .
      dockerfile: services/ml_analyzer/Dockerfile
    container_name: arbees-ml-analyzer
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./:/app
      - ./reports:/app/reports
    profiles:
      - legacy

  # DISABLED: futures_monitor - will revive later when everything else works
  # futures_monitor:
  #   build:
  #     context: .
  #     dockerfile: services/futures_monitor/Dockerfile
  #   container_name: arbees-futures-monitor
  #   depends_on:
  #     timescaledb:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #   env_file:
  #     - .env
  #   environment:
  #     DATABASE_URL: postgresql://${POSTGRES_USER:-arbees}:${POSTGRES_PASSWORD}@timescaledb:5432/${POSTGRES_DB:-arbees}
  #     REDIS_URL: redis://redis:6379
  #     LOG_LEVEL: INFO
  #     # Futures Monitor configuration
  #     FUTURES_LOOKAHEAD_HOURS: "48"
  #     FUTURES_MIN_HOURS_BEFORE_START: "0.5"
  #     FUTURES_HANDOFF_MINUTES: "15"
  #     FUTURES_DISCOVERY_INTERVAL: "1800"
  #     FUTURES_PRICE_POLL_INTERVAL: "60"
  #     FUTURES_MIN_EDGE: "5.0"
  #     FUTURES_LINE_MOVEMENT_ALERT: "3.0"
  #     FUTURES_MAX_GAMES: "50"
  #     # Market discovery mode: 'rust' uses Rust discovery service, 'local' uses Python clients
  #     MARKET_DISCOVERY_MODE: "rust"
  #   volumes:
  #     - ./:/app
  #   restart: unless-stopped
  #   profiles:
  #     - full

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: arbees-frontend
    depends_on:
      - api
    ports:
      - "3000:80"
    profiles:
      - full

  # ==========================================================================
  # Phase 3: VPN + Polymarket Price Shard (geo-bypass for Polymarket CLOB/WS)
  # ==========================================================================
  #
  # VPN SCOPE (minimal blast radius):
  # - ONLY polymarket_monitor needs VPN (CLOB/WebSocket are geo-blocked)
  # - market-discovery-rust does NOT need VPN (Gamma API is public)
  # - All other services access Polymarket prices via Redis
  #
  # AWS NOTE: Fargate does NOT support NET_ADMIN or /dev/net/tun.
  # For AWS deployment, use either:
  # - ECS EC2 launch type for VPN task
  # - EU-hosted proxy instead of VPN
  # ==========================================================================

  vpn:
    image: qmcgaw/gluetun
    container_name: arbees-vpn
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    # Expose ZMQ port for polymarket_monitor (uses network_mode: service:vpn)
    expose:
      - "5556"
    env_file:
      - .env
    environment:
      # VPN Failover: gluetun will try servers in these countries in order
      # Netherlands is preferred (closest to Polymarket's EU servers), with fallbacks
      - SERVER_COUNTRIES=${VPN_COUNTRIES:-Netherlands,Germany,Belgium,France}
      # Automatic server rotation on failure
      - VPN_PORT_FORWARDING=off
      # Retry settings for connection stability
      - OPENVPN_VERBOSITY=1
      # Control plane for server switching
      - PUBLICIP_API=ipinfo
      - PUBLICIP_PERIOD=60s
      # Use Docker's embedded DNS (127.0.0.11) so containers using network_mode:service:vpn can resolve hostnames
      - DNS_KEEP_NAMESERVER=on
    healthcheck:
      # Use HTTP (not HTTPS) to avoid CA/cert issues inside minimal images causing false "unhealthy".
      # Check both connectivity and that we're in an EU country (geo-bypass check)
      test: [ "CMD", "wget", "-q", "--spider", "http://ipinfo.io/json" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    restart: unless-stopped
    # Note: deploy.restart_policy is for Swarm mode only; use 'restart' for standalone
    profiles:
      - full
      - vpn

  # Crypto Spot Price Monitor - Real-time BTC/ETH/SOL spot prices via WebSocket
  crypto-spot-monitor:
    build:
      context: .
      dockerfile: services/crypto_spot_monitor/Dockerfile
    container_name: arbees-crypto-spot-monitor
    environment:
      ZMQ_PUB_ENDPOINT: "tcp://*:5560"
      MONITORED_ASSETS: "BTC,ETH,SOL"
      LOG_LEVEL: "INFO"
    expose:
      - "5560"
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
    restart: unless-stopped
    profiles:
      - full
      - crypto

  # Polymarket Price Shard - publishes prices to Redis for all consumers
  polymarket_monitor:
    build:
      context: .
      dockerfile: services/polymarket_monitor/Dockerfile
    container_name: arbees-polymarket-monitor
    network_mode: "service:vpn"
    depends_on:
      vpn:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # ZMQ configuration for low-latency price publishing
      # Note: Since using network_mode: service:vpn, port 5556 is exposed via vpn container
      ZMQ_PUB_PORT: "5556"
    volumes:
      # DEBUG MODE: write NDJSON instrumentation to the host workspace file
      - ./.cursor:/app/.cursor
    restart: unless-stopped
    profiles:
      - full
      - vpn

  # Kalshi Price Monitor - publishes prices to Redis for all consumers
  # No VPN needed - Kalshi API is accessible from US
  kalshi_monitor:
    build:
      context: .
      dockerfile: services/kalshi_monitor/Dockerfile
    container_name: arbees-kalshi-monitor
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    environment:
      # ZMQ configuration for low-latency price publishing
      ZMQ_PUB_PORT: "5555"
    expose:
      - "5555"
    restart: unless-stopped
    profiles:
      - full

volumes:
  timescaledb_data:
  redis_data:
  signal_cli_data:


networks:
  default:
    name: arbees-network
